{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Tce3stUlHN0L"
      },
      "source": [
        "##### Copyright 2020 The TensorFlow Authors."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "colab": {},
        "colab_type": "code",
        "id": "tuOe1ymfHZPu"
      },
      "outputs": [],
      "source": [
        "#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "qFdPvlXBOdUN"
      },
      "source": [
        "# Better ML Engineering with Machine Learning Metadata\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "MfBg1C5NB3X0"
      },
      "source": [
        "\u003ctable class=\"tfo-notebook-buttons\" align=\"left\"\u003e\n",
        "  \u003ctd\u003e\n",
        "    \u003ca target=\"_blank\" href=\"https://www.tensorflow.org/tfx/tutorials/mlmd_tutorial\"\u003e\u003cimg src=\"https://www.tensorflow.org/images/tf_logo_32px.png\" /\u003eView on TensorFlow.org\u003c/a\u003e\n",
        "  \u003c/td\u003e\n",
        "  \u003ctd\u003e\n",
        "    \u003ca target=\"_blank\" href=\"https://colab.research.google.com/github/tensorflow/tfx/blob/master/docs/tutorials/mlmd_tutorial.ipynb\"\u003e\u003cimg src=\"https://www.tensorflow.org/images/colab_logo_32px.png\" /\u003eRun in Google Colab\u003c/a\u003e\n",
        "  \u003c/td\u003e\n",
        "  \u003ctd\u003e\n",
        "    \u003ca target=\"_blank\" href=\"https://github.com/tensorflow/docs/blob/master/tools/templates/notebook.ipynb\"\u003e\u003cimg src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\" /\u003eView source on GitHub\u003c/a\u003e\n",
        "  \u003c/td\u003e\n",
        "  \u003ctd\u003e\n",
        "    \u003ca href=\"https://storage.googleapis.com/tensorflow_docs/docs/tools/templates/notebook.ipynb\"\u003e\u003cimg src=\"https://www.tensorflow.org/images/download_logo_32px.png\" /\u003eDownload notebook\u003c/a\u003e\n",
        "  \u003c/td\u003e\n",
        "\u003c/table\u003e"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "xHxb-dlhMIzW"
      },
      "source": [
        "Assume a scenario where you set up a production ML pipeline to classify pictures of irises, a kind of flower. The pipeline ingests your training data, trains and evaluates a model, and pushes it to production. \n",
        "\n",
        "However, some time later, when you try using this model with a larger dataset that comprises of images of different kinds of flowers, you observe that your model does not behave as expected and starts classifying roses and lilies as types of irises.\n",
        "\n",
        "At this point, you are interested in knowing:\n",
        "\n",
        "* What is the most efficient way to debug the model when the only available artifact is the model in production?\n",
        "* Which training dataset was used to train the model?\n",
        "* Which training run led to this erroneous model?\n",
        "* Where are the model evaluation results? \n",
        "* Where to begin debugging?\n",
        "\n",
        "[Machine Learning Metadata (MLMD)](https://github.com/google/ml-metadata) is a library that leverages the metadata associated with ML models to help you answer these questions and more. MLMD enables you to reliably track the artifacts and lineage associated with the various components of your ML pipeline.   \n",
        "\n",
        "In this tutorial, you set up a TFX Pipeline to create a models that classifies Iris flowers into three species - Iris setosa, Iris virginica, and Iris versicolor based on the length and width measurements of their petals and sepals. You then use MLMD to track the lineage of pipeline components."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "3rGF8hLibz6p"
      },
      "source": [
        "## TFX Pipelines in Colab\n",
        "\n",
        "Colab is a lightweight development environment which differs significantly from a production environment. In production, you may have various pipeline components like data ingestion, transformation, model training, run histories, etc. across multiple, distributed systems. For this tutorial, you should be aware that siginificant differences exist in Orchestration and Metadata storage - it is all handled locally within Colab.\n",
        "\n",
        "### Pipeline Orchestration\n",
        "\n",
        "To deploy TFX in a production environment, you use an orchestrator. Orchestrators take the definition of a pipeline and run it. Common orchestrators include Apache Airflow, Kubeflow, or Apache Beam. In the Colab environment, the pipeline is defined within the notebook and the notebook itself is the orchestrator and runs each TFX component as you execute the code cells in the notebook. You can read more about orchestrators [here](https://www.tensorflow.org/tfx/guide/custom_orchestrator).\n",
        "\n",
        "### Metadata storage\n",
        "\n",
        "When you deploy TFX pipelines in production, MLMD stores metadata properties in a database like MySQL or SQLite, and stores the metadata payloads in a persistent store on your filesystem. In the Colab environment, metadata properties and payloads are stored in the `/tmp` directory on the Colab server. \n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "MUXex9ctTuDB"
      },
      "source": [
        "## Setup\n",
        "\n",
        "Import all required libraries."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "mQV-Cget1S8t"
      },
      "source": [
        "### Install and import TFX"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "82jOhrcA36YA"
      },
      "outputs": [],
      "source": [
        "!pip install --quiet tfx"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "OD2cRhwM3ez2"
      },
      "source": [
        "You must restart the Colab runtime after installing TFX. Select **Runtime \u003e Restart runtime** from the Colab menu."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "ohOztGn2wc1z"
      },
      "source": [
        "### Import other libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "IqR2PQG4ZaZ0"
      },
      "outputs": [],
      "source": [
        "import base64\n",
        "import csv\n",
        "import json\n",
        "import os\n",
        "import requests\n",
        "import tempfile\n",
        "import urllib\n",
        "import pprint\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "KY8ROY_x1wZ2"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import tfx"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "hWCiTxFo32jk"
      },
      "source": [
        "Import TFX component classes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "qgXWGGmK1rhP"
      },
      "outputs": [],
      "source": [
        "from tfx.components.evaluator.component import Evaluator\n",
        "from tfx.components.example_gen.csv_example_gen.component import CsvExampleGen\n",
        "from tfx.components.pusher.component import Pusher\n",
        "from tfx.components.schema_gen.component import SchemaGen\n",
        "from tfx.components.statistics_gen.component import StatisticsGen\n",
        "from tfx.components.trainer.component import Trainer\n",
        "from tfx.components.transform.component import Transform\n",
        "from tfx.components.base import executor_spec\n",
        "from tfx.components.trainer.executor import GenericExecutor\n",
        "from tfx.orchestration.experimental.interactive.interactive_context import InteractiveContext\n",
        "from tfx.proto import evaluator_pb2\n",
        "from tfx.proto import pusher_pb2\n",
        "from tfx.proto import trainer_pb2\n",
        "from tfx.utils.dsl_utils import external_input\n",
        "\n",
        "from tensorflow_metadata.proto.v0 import anomalies_pb2\n",
        "from tensorflow_metadata.proto.v0 import schema_pb2\n",
        "from tensorflow_metadata.proto.v0 import statistics_pb2\n",
        "\n",
        "import tensorflow_transform as tft\n",
        "from tensorflow_transform import coders as tft_coders\n",
        "from tensorflow_transform.tf_metadata import dataset_schema\n",
        "from tensorflow_transform.tf_metadata import schema_utils\n",
        "\n",
        "import tensorflow_model_analysis as tfma\n",
        "import tensorflow_data_validation as tfdv\n",
        "\n",
        "from tfx.components import ResolverNode\n",
        "from tfx.dsl.experimental import latest_blessed_model_resolver\n",
        "from tfx.types import Channel\n",
        "from tfx.types.standard_artifacts import Model\n",
        "from tfx.types.standard_artifacts import ModelBlessing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "JKo31y2L5hCy"
      },
      "source": [
        "Import the MLMD library."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "FNYHX6zA5gE5"
      },
      "outputs": [],
      "source": [
        "import ml_metadata\n",
        "from ml_metadata.metadata_store import metadata_store\n",
        "from ml_metadata.proto import metadata_store_pb2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "UhNtHfuxCGVy"
      },
      "source": [
        "## Download the dataset\n",
        "\n",
        "Download the [Iris dataset](https://archive.ics.uci.edu/ml/datasets/iris) dataset to use in this tutorial. The dataset consists of flower data for 150 Iris flowers which belong to one of three species - Iris setosa, Iris virginica, and Iris versicolor."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "B_NibNnjzGHu"
      },
      "outputs": [],
      "source": [
        "DATA_PATH = 'https://raw.githubusercontent.com/tensorflow/tfx/master/tfx/examples/iris/data/iris.csv'\n",
        "_data_root = tempfile.mkdtemp(prefix='tfx-data')\n",
        "_data_filepath = os.path.join(_data_root, \"iris.csv\")\n",
        "urllib.request.urlretrieve(DATA_PATH, _data_filepath)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "8NXg2bGA19HJ"
      },
      "source": [
        "## Create an InteractiveContext\n",
        "\n",
        "To run TFX components interactively in this notebook, create an `InteractiveContext`. The `InteractiveContext` uses a temporary directory with an ephemeral MLMD database instance. Note that calls to `InteractiveContext` are no-ops outside the Colab environment."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "bytrDFKh40mi"
      },
      "outputs": [],
      "source": [
        "int_context = InteractiveContext()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "e-58fa9S6Nao"
      },
      "source": [
        "## Construct the TFX Pipeline\n",
        "\n",
        "A TFX pipeline consists of several components that perform different aspects of the ML workflow. In this notebook, you create and run the `ExampleGen`, `StatisticsGen`, `SchemaGen`, and `TrainerGen` components. Refer to the [components tutorial](https://www.tensorflow.org/tfx/tutorials/tfx/components_keras) for more information on TFX pipeline components."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "bnnq7Gf8CHZJ"
      },
      "source": [
        "### Instantiate and run the ExampleGen Component"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "H9zaBZh3C_9x"
      },
      "outputs": [],
      "source": [
        "input_data = external_input(_data_root)\n",
        "example_gen = CsvExampleGen(input=input_data)\n",
        "\n",
        "# Run the ExampleGen component using the InteractiveContext\n",
        "int_context.run(example_gen)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "nqxye_p1DLmf"
      },
      "source": [
        "### Instantiate and run the StatisticsGen Component"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "s67sHU_vDRds"
      },
      "outputs": [],
      "source": [
        "statistics_gen = StatisticsGen(examples=example_gen.outputs['examples'])\n",
        "\n",
        "# Run the StatisticsGen component using the InteractiveContext\n",
        "int_context.run(statistics_gen)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "xib9oRb_ExjJ"
      },
      "source": [
        "### Instantiate and run the SchemaGen Component"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "csmD4CSUE3JT"
      },
      "outputs": [],
      "source": [
        "infer_schema = SchemaGen(statistics=statistics_gen.outputs['statistics'],\n",
        "                         infer_feature_shape = True)\n",
        "\n",
        "# Run the SchemaGen component using the InteractiveContext\n",
        "int_context.run(infer_schema)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "_pYNlw7BHUjP"
      },
      "source": [
        "### Instantiate and run the Trainer Component\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "MTxf8xs_kKfG"
      },
      "outputs": [],
      "source": [
        "# Define the module file for the Trainer component\n",
        "trainer_module_file = 'iris_trainer.py'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "f3nLHEmUkRUw"
      },
      "outputs": [],
      "source": [
        "# Define the training algorithm for the Trainer module file \n",
        "%%writefile {trainer_module_file}\n",
        "import os\n",
        "from typing import List, Text\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "\n",
        "from tfx.components.trainer.executor import TrainerFnArgs\n",
        "from tfx.components.trainer.fn_args_utils import FnArgs\n",
        "\n",
        "# Iris dataset has 150 records, and is split into training and evaluation \n",
        "# datasets in a 2:1 split\n",
        "\n",
        "_TRAIN_DATA_SIZE = 100\n",
        "_EVAL_DATA_SIZE = 50\n",
        "_TRAIN_BATCH_SIZE = 100\n",
        "_EVAL_BATCH_SIZE = 50\n",
        "\n",
        "_FEATURES = {\n",
        "    'sepal_length': tf.io.FixedLenFeature([], dtype=tf.float32, default_value=0),\n",
        "    'sepal_width': tf.io.FixedLenFeature([], dtype=tf.float32, default_value=0),\n",
        "    'petal_length': tf.io.FixedLenFeature([], dtype=tf.float32, default_value=0),\n",
        "    'petal_width': tf.io.FixedLenFeature([], dtype=tf.float32, default_value=0),\n",
        "    'variety': tf.io.FixedLenFeature([], dtype=tf.int64, default_value=0)\n",
        "}\n",
        "\n",
        "_LABEL_KEY = 'variety'\n",
        "\n",
        "_FEATURE_KEYS = ['sepal_length', 'sepal_width', 'petal_length', 'petal_width']\n",
        "\n",
        "def _gzip_reader_fn(filenames):\n",
        "  return tf.data.TFRecordDataset(filenames, compression_type='GZIP')\n",
        "\n",
        "def _input_fn(file_pattern: List[Text],\n",
        "              batch_size: int = 200):\n",
        "  dataset = tf.data.experimental.make_batched_features_dataset(\n",
        "            file_pattern=file_pattern,\n",
        "            batch_size=batch_size,\n",
        "            features=_FEATURES,\n",
        "            reader=_gzip_reader_fn,\n",
        "            label_key=_LABEL_KEY)\n",
        "  \n",
        "  return dataset\n",
        "  \n",
        "def _build_keras_model():\n",
        "  inputs = [keras.layers.Input(shape = (1,), name = f) for f in _FEATURE_KEYS]\n",
        "  d = keras.layers.concatenate(inputs)\n",
        "  d = keras.layers.Dense(8, activation = 'relu')(d)\n",
        "  d = keras.layers.Dense(8, activation = 'relu')(d)\n",
        "  outputs = keras.layers.Dense(3, activation = 'softmax')(d)\n",
        "  model = keras.Model(inputs=inputs, outputs=outputs)\n",
        "  model.compile(optimizer = 'adam',\n",
        "                loss = 'sparse_categorical_crossentropy',\n",
        "                metrics= [keras.metrics.SparseCategoricalAccuracy()])\n",
        "  return model\n",
        "\n",
        "def run_fn(fn_args: TrainerFnArgs):\n",
        "  train_dataset = _input_fn(fn_args.train_files, batch_size=_TRAIN_BATCH_SIZE)\n",
        "  eval_dataset = _input_fn(fn_args.eval_files, batch_size=_EVAL_BATCH_SIZE)\n",
        "  \n",
        "  model = _build_keras_model()\n",
        "\n",
        "  print(model.summary())\n",
        "\n",
        "  steps_per_epoch = _TRAIN_DATA_SIZE / _TRAIN_BATCH_SIZE\n",
        "\n",
        "  model.fit(train_dataset, \n",
        "            epochs=int(fn_args.train_steps / steps_per_epoch),\n",
        "            steps_per_epoch=steps_per_epoch,\n",
        "            validation_data=eval_dataset,\n",
        "            validation_steps=fn_args.eval_steps)\n",
        "  model.save(fn_args.serving_model_dir, save_format='tf')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "qcmSNiqq5QaV"
      },
      "source": [
        "Run the `Trainer` component."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "4AzsMk7oflMg"
      },
      "outputs": [],
      "source": [
        "trainer = Trainer(\n",
        "    module_file=os.path.abspath(trainer_module_file),\n",
        "    custom_executor_spec=executor_spec.ExecutorClassSpec(GenericExecutor),\n",
        "    examples=example_gen.outputs['examples'],\n",
        "    schema=infer_schema.outputs['schema'],\n",
        "    train_args=trainer_pb2.TrainArgs(num_steps=100),\n",
        "    eval_args=trainer_pb2.EvalArgs(num_steps=50))\n",
        "\n",
        "int_context.run(trainer)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "gdCq5c0f5MyA"
      },
      "source": [
        "### Evaluate and push the model\n",
        "\n",
        "Use the `Evaluator` component to evaluate and 'bless' the model before using the `Pusher` component to push the model to a serving directory."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "NDx-fTUb6RUU"
      },
      "outputs": [],
      "source": [
        "_serving_model_dir = os.path.join(tempfile.mkdtemp(), 'serving_model/iris_classification')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "PpS4-wCf6eLR"
      },
      "outputs": [],
      "source": [
        "eval_config = tfma.EvalConfig(model_specs=[tfma.ModelSpec(label_key ='variety')],\n",
        "                              metrics_specs =[tfma.MetricsSpec(metrics = \n",
        "                                                               [tfma.MetricConfig(class_name='ExampleCount'),\n",
        "                                                               tfma.MetricConfig(class_name='BinaryAccuracy',\n",
        "                                                                  threshold=tfma.MetricThreshold(\n",
        "                                                                      value_threshold=tfma.GenericValueThreshold(\n",
        "                                                                          lower_bound={'value': 0.5}),\n",
        "                                                                      change_threshold=tfma.GenericChangeThreshold(\n",
        "                                                                          direction=tfma.MetricDirection.HIGHER_IS_BETTER,\n",
        "                                                                          absolute={'value': -1e-10})))])],\n",
        "                              slicing_specs = [tfma.SlicingSpec(),\n",
        "                                               tfma.SlicingSpec(feature_keys=['sepal_length'])])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "kFuH1YTh8vSf"
      },
      "outputs": [],
      "source": [
        "model_resolver = ResolverNode(\n",
        "      instance_name='latest_blessed_model_resolver',\n",
        "      resolver_class=latest_blessed_model_resolver.LatestBlessedModelResolver,\n",
        "      model=Channel(type=Model),\n",
        "      model_blessing=Channel(type=ModelBlessing))\n",
        "int_context.run(model_resolver)\n",
        "\n",
        "evaluator = Evaluator(\n",
        "    examples=example_gen.outputs['examples'],\n",
        "    model=trainer.outputs['model'],\n",
        "    baseline_model=model_resolver.outputs['model'],\n",
        "    eval_config=eval_config)\n",
        "int_context.run(evaluator)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "NCV9gcCQ966W"
      },
      "outputs": [],
      "source": [
        "pusher = Pusher(\n",
        "    model=trainer.outputs['model'],\n",
        "    model_blessing=evaluator.outputs['blessing'],\n",
        "    push_destination=pusher_pb2.PushDestination(\n",
        "        filesystem=pusher_pb2.PushDestination.Filesystem(\n",
        "            base_directory=_serving_model_dir)))\n",
        "int_context.run(pusher)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "9K7RzdBzkru7"
      },
      "source": [
        "Running the TFX pipeline populates the MLMD Database. In the next section, you use the MLMD API to query this database for metadata information. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "6GRCGQu7RguC"
      },
      "source": [
        "## Query the MLMD Database\n",
        "\n",
        "The MLMD database stores three types of metadata: \n",
        "\n",
        "*    Metadata about the pipeline and lineage information associated with the pipeline components\n",
        "*    Metadata about artifacts that were generated during the pipeline run\n",
        "*    Metadata about the executions of the pipeline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "o0xVYqAkJybK"
      },
      "source": [
        "Set up the metadata store with the `InteractiveContext` defined previously to query the MLMD database."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "P1p38etAv0kC"
      },
      "outputs": [],
      "source": [
        "md_store = metadata_store.MetadataStore(int_context.metadata_connection_config)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "1B-jRNH0M0k4"
      },
      "source": [
        "In a production environment, when you encounter erroneous results in a model pushed through your TFX pipeline, you can query the MLMD database to trace the lineage of your pipeline components and use it to find the artifacts that correspond to the pushed model. \n",
        "\n",
        "First, query the metadata store for pushed models:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "bUv_EI-bEMMu"
      },
      "outputs": [],
      "source": [
        "def get_pushed_models(store): \n",
        "  return store.get_artifacts_by_type(\"PushedModel\")\n",
        "\n",
        "# In this example, there is only one pushed model \n",
        "pushed_model = get_pushed_models(md_store)[0]\n",
        "print(pushed_model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "f5Mz4vfP6wHO"
      },
      "source": [
        "Get the training data associated with this model. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "3VINTDY07UPI"
      },
      "outputs": [],
      "source": [
        "def get_training_data(store, model):\n",
        "  all_models = get_pushed_models(store)\n",
        "  for models in all_models:\n",
        "    if models.id == model.id:\n",
        "      train_data = store.get_artifacts_by_type(\"Examples\")\n",
        "      return train_data\n",
        "  return None\n",
        "\n",
        "td = get_training_data(md_store, pushed_model)\n",
        "if td is not None:\n",
        "  print(td)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "GgTMTaew_3Fe"
      },
      "source": [
        "Now that you have the training data that the model trained with, query the database again to find the training step (execution):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "9s5799H6AHGD"
      },
      "outputs": [],
      "source": [
        "def get_training_step(store, model):\n",
        "  all_models = get_pushed_models(store)\n",
        "  for models in all_models:\n",
        "    if models.id == model.id:\n",
        "      train_step = store.get_executions_by_type(\"tfx.components.trainer.component.Trainer\")\n",
        "      return train_step\n",
        "  return None\n",
        "\n",
        "ts = get_training_step(md_store, pushed_model)\n",
        "if ts is not None:\n",
        "  print(ts)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "QplqvReHPtic"
      },
      "source": [
        "You can also trace the lineage of the pushed model by querying all of its upstream artifacts and executions."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "rie2ZEyoKI9R"
      },
      "outputs": [],
      "source": [
        "pp = pprint.PrettyPrinter()\n",
        "\n",
        "def get_upstream_artifacts_and_executions(artifact):\n",
        "  artifact_types = execution_types = {} \n",
        "  for atype in md_store.get_artifact_types():\n",
        "    artifact_types[atype.id] = atype.name\n",
        "  for etype in md_store.get_execution_types():\n",
        "    execution_types[etype.id] = etype.name\n",
        "\n",
        "  q = artifact\n",
        "  ra = {}\n",
        "  re = {}\n",
        "  ra[artifact_types[q.type_id]] = {q.id}\n",
        "  eval_re = True\n",
        "  while True:\n",
        "    ra_len = len(ra)\n",
        "    re_len = len(re)     \n",
        "    if eval_re:\n",
        "      eval_re = False\n",
        "      executions = md_store.get_executions_by_id(\n",
        "          [e.execution_id for e in md_store.get_events_by_artifact_ids(\n",
        "              [aid for aid in sum([list(v) for v in ra.values()], [])]) \n",
        "          if e.type == metadata_store_pb2.Event.OUTPUT])\n",
        "      for ex in executions:\n",
        "        re.setdefault(execution_types[ex.type_id], set()).add(ex.id)       \n",
        "    else:\n",
        "      eval_re = True\n",
        "      artifacts = md_store.get_artifacts_by_id(\n",
        "          [e.artifact_id for e in md_store.get_events_by_execution_ids(\n",
        "              [exid for exid in sum([list(v) for v in re.values()], [])]) \n",
        "          if e.type == metadata_store_pb2.Event.INPUT])\n",
        "      for a in artifacts:\n",
        "        ra.setdefault(artifact_types[a.type_id], set()).add(a.id)\n",
        "    if (ra_len == len(ra) and re_len == len(re)):\n",
        "      break\n",
        "  return ra, re\n",
        "\n",
        "ancestor_aid, ancestor_eid = get_upstream_artifacts_and_executions(pushed_model)\n",
        "print(\"Upstream Artifacts `RA`:\")\n",
        "pp.pprint(ancestor_aid)\n",
        "print(\"\\nUpstream Executions `RE`:\")\n",
        "pp.pprint(ancestor_eid)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "CYzlTckHClxC"
      },
      "source": [
        "## Summary\n",
        "\n",
        "In this tutorial, you learned how to use MLMD to analyze the lineage of the components of your TFX pipeline. To learn more about how to use MLMD, check out these additional resources:\n",
        "\n",
        "* [MLMD API documentation](https://www.tensorflow.org/tfx/ml_metadata/api_docs/python/mlmd)\n",
        "* [MLMD guide](https://www.tensorflow.org/tfx/guide/mlmd)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "Tce3stUlHN0L"
      ],
      "name": "mlmd_tutorial.ipynb",
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
